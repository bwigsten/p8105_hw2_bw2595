p8105\_hw2\_bw2595
================
Blair Wigsten
10/4/2019

# Problem 1: Mr. Trash Wheel Dataset

``` r
library(tidyverse)
```

    ## ── Attaching packages ──────────────────────────────────────────────── tidyverse 1.2.1 ──

    ## ✔ ggplot2 3.2.1     ✔ purrr   0.3.2
    ## ✔ tibble  2.1.3     ✔ dplyr   0.8.3
    ## ✔ tidyr   1.0.0     ✔ stringr 1.4.0
    ## ✔ readr   1.3.1     ✔ forcats 0.4.0

    ## ── Conflicts ─────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(knitr)
```

## Read and clean the Mr. Trash Wheel dataset

``` r
library(readxl)
trashwheel_data = read_excel("data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 1) %>%
  janitor::clean_names() %>%
  select(-x15, -x16, -x17) %>%
  drop_na(dumpster) %>%
  rename(trash_weight_tons = weight_tons,
         trash_volume_cubicyards = volume_cubic_yards) %>%
  mutate(sports_balls = as.integer(round(sports_balls, 0)))
```

    ## New names:
    ## * `` -> ...15
    ## * `` -> ...16
    ## * `` -> ...17

  - Using the first sheet in the Excel document to import the Mr. Trash
    Wheel data, we clean the variable names to lower snake case. Then,
    using the select argument, we eliminate variables with text for
    entries (x15, x16, and x17). To drop rows that represent monthly
    totals (do not have dumpster specific data), we drop any rows that
    contain “N/A” within the dumpster variable. In order to create
    meaningful variable names, we change the weight\_tons to
    trash\_weight\_tons, and volume\_cubic\_yards to
    trash\_volume\_cubicyards. Finally, we use mutate to round the
    sports\_balls variable to 0 decimal places, then convert that result
    to an integer
variable.

## Read and clean precipitation data for 2017 and 2018

``` r
precip_2018 = read_excel("data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 5, skip = 1) %>%
  janitor::clean_names() %>%
  drop_na() %>%
  mutate(year = 2018)
```

  - This loads and cleans the 2018 precipitation data within the
    Trashwheel Excel document, sheet number 5. We skip the first row of
    the excel sheet, as our variable names start on row 2 of the sheet.
    We convert all variable names to lower snake case, drop any rows
    with “N/A”, and add a variable “year” where each observation has a
    value of
2018.

<!-- end list -->

``` r
precip_2017 = read_excel("data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 6, skip = 1) %>%
  janitor::clean_names() %>%
  drop_na() %>%
  mutate(year = 2017)
```

  - This loads and cleans the 2017 precipitation data within the
    Trashwheel Excel document, sheet number 6. We skip the first row of
    the excel sheet, as our variable names start on row 2 of the sheet.
    We convert all variable names to lower snake case, drop any rows
    with “N/A”, and add a variable “year” where each observation has a
    value of
2017.

## Combine precipitation datasets and convert month to a character variable

``` r
precip_2017_2018 =
  bind_rows(precip_2017, precip_2018) %>%
  janitor::clean_names() %>%
  select(year, month, total) %>%
  arrange(year, month) %>%
  mutate(
    month = as.numeric(month), 
    month = month.abb[month])
```

  - Using bind rows, we stack datasets on top of each other. Then clean
    the variable names, keep the year, month, and total variables,
    arrange by year and month, then convert month to a character
    variable with their 3 letter abbreviations.

## Paragraph describing the data using inline code

There are 24 observations in the combined precipitation dataset and 344
observations in the trashwheel dataset. The total precipitation in 2018
was 70.33. The key variables in both the trashwheel dataset and
precipitation\_2017\_2018 are month and year, as they are in both
datasets. Other key variables for analysis include precipitation totals,
trash weight, trash volume, and homes powered, as these would be
relevant for any analysis into the effectiveness of the trash wheel. The
median number of sports balls collected in 2017 is 8.

# Problem 2: FiveThirtyEight Data

## Load and clean data from pols-month

``` r
pols = read_csv(file = "fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day")) %>%
  mutate(
    month = as.numeric(month), 
    month = month.abb[month],
    prez_gop = recode(prez_gop, `1` = "gop", `2` = "gop",`0` = "dem"),
    president = prez_gop) %>%
  select(year, month, everything(), -prez_dem, -prez_gop, -day)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

  - We clean the variable names of the pols data, separate the date into
    year, month, and day variables. Using mutate argument, we convert
    all month names to the 3 letter abbreviations, recode the prez\_gop
    group to gop if 1 or 2, and dem if 0. Then, we set the newly created
    president variable to equal the prez\_gop variable, then drop the
    day, prez\_dem, and prez\_gop variables. This dataset is already
    arranged by year and month for merging later.

## Load and clean snp data

``` r
snp = read_csv(file = "fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  rename(sp_close = close) %>%
  separate(date, into = c("month", "day", "year")) %>%
  mutate(
    month = as.numeric(month),
    month = month.abb[month]) %>%
  select(year, month, sp_close, -day) 
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

  - We clean the variable names of the snp data, separate the date into
    year, month, and day variables. We arrange the dataset by year and
    month. For clarity, we rename the variable “close” to “spclose”.
    Then, using the mutate argument, we convert all month names to the 3
    letter abbreviations. We select the year, month, and sp\_close
    variables to keep in the final cleaned
dataset.

## Load and clean unemployment data

``` r
unemployment = read.csv(file = "fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment rate") %>%
  rename(year = Year) %>%
  mutate(
    year = as.character(year))
```

  - Here, I did not clean the variable names using janitor in order to
    pivot first and merge easier later (month names stay with capital
    first letters). We pivot longer to switch to long format. Then, we
    rename the “Year” variable to “year” in order to match the case of
    the snp and pols datasets to merge later. Finally, we convert the
    year variable to a character variable to match the snp and pols
    datasets for future merging.

## Join the datasets by merging snp into pols

``` r
snp_pols =
  left_join(pols, snp, by = c("year", "month")) 
```

  - Using left join, we merge snp into pols to produce the snp\_pols
    dataset.

## Merge unemployment into snp\_pols

``` r
final_data = left_join(snp_pols, unemployment, by = c("year", "month"))
```

  - Using left join, we merge unemployment into snp\_pols to produce the
    final\_data dataset.

## Paragraph describing the final dataset

\*The pols dataset contains information regarding presidential,
senatorial, house, and governor party information. We are given the
counts per month of each year (from 1947 through 2015) for party
affiliation in each of the government branches. The snp dataset contains
information for months of each year (1950 through 2015) regarding the
closing value of the S\&P stock index. The unemployment dataset contains
information regarding the unemployment rate associated with months of
each year (1948 through 2015). After merging snp into pols by year and
month, and merging the unemployment dataset with the result, also by
year and month, we have the final\_data set. This dataset contains each
month and year observation from all three original datasets, and all
variables, besides day, from each dataset. There are missing values for
certain variables in some months/years where data was not available but
was included in this cleaning to be conservative. The final dataset has
822 observations and 11 variables. The range of years included is from
January 1947 to June 2015. Key variables in this analysis would inlude
the year and month, as those are how we joined datasets. Other important
variables for analysis could include president, sp\_close, and
unemployment to test associations between the presidential status and
economic indicators.

# Problem 3: Popularity of Baby Names

## Load and tidy the data

``` r
baby_names = read_csv(file = "data/Popular_Baby_Names.csv") %>%
  janitor::clean_names() %>%
  rename(first_name = childs_first_name,
         birth_year = year_of_birth) %>%
  mutate(
    first_name = str_to_lower(first_name),
    ethnicity = str_to_lower(ethnicity),
    gender = str_to_lower(gender)) %>%
  mutate(
    ethnicity = if_else(ethnicity == "black non hisp", "black non hispanic", ethnicity),
    ethnicity = if_else(ethnicity == "asian and paci", "asian and pacific islander", ethnicity),
    ethnicity = if_else(ethnicity == "white non hisp", "white non hispanic", ethnicity)) %>%
  distinct()
```

    ## Parsed with column specification:
    ## cols(
    ##   `Year of Birth` = col_double(),
    ##   Gender = col_character(),
    ##   Ethnicity = col_character(),
    ##   `Child's First Name` = col_character(),
    ##   Count = col_double(),
    ##   Rank = col_double()
    ## )

  - We clean variable names, rename variables to be more descriptive,
    convert all observations to lower case, then delete duplicate rows
    using distinct. Finally, since ethnicity names change over time, we
    create cohesive categorical indicators for each inconsistent
    predictor (black non hispanic, asian and pacific islander, and white
    non hispanic).

## Produce a table for the rank in popularity of Olivia over time

### Olivia Popularity (Rank) Over Time by Ethnicity

``` r
olivia = baby_names %>%
  filter(first_name == "olivia") %>%
  select(birth_year, ethnicity, rank) %>%
  arrange(birth_year) %>%
  pivot_wider(
    names_from = "birth_year", 
    values_from = "rank")

kable(olivia)
```

| ethnicity                  | 2011 | 2012 | 2013 | 2014 | 2015 | 2016 |
| :------------------------- | ---: | ---: | ---: | ---: | ---: | ---: |
| asian and pacific islander |    4 |    3 |    3 |    1 |    1 |    1 |
| black non hispanic         |   10 |    8 |    6 |    8 |    4 |    8 |
| hispanic                   |   18 |   22 |   22 |   16 |   16 |   13 |
| white non hispanic         |    2 |    4 |    1 |    1 |    1 |    1 |

## Produce a table for the most popular boy name by ethnicity and year

### Most Popular Boy Name by Ethnicity Each Year

``` r
male_name = baby_names %>%
  filter(gender == "male", rank == "1") %>%
  select(birth_year, first_name, ethnicity) %>%
  arrange(birth_year) %>%
  pivot_wider(
    names_from = "birth_year",
    values_from = "first_name")

kable(male_name)
```

| ethnicity                  | 2011    | 2012   | 2013   | 2014   | 2015   | 2016   |
| :------------------------- | :------ | :----- | :----- | :----- | :----- | :----- |
| asian and pacific islander | ethan   | ryan   | jayden | jayden | jayden | ethan  |
| black non hispanic         | jayden  | jayden | ethan  | ethan  | noah   | noah   |
| hispanic                   | jayden  | jayden | jayden | liam   | liam   | liam   |
| white non hispanic         | michael | joseph | david  | joseph | david  | joseph |

## Produce a scatterplot of number of male, white non hispanic children with a name against rank in popularity of that name in 2016

``` r
white_male = baby_names %>%
  filter(gender == "male", birth_year == "2016", ethnicity == "white non hispanic") 

white_male_scatterplot = ggplot(white_male, aes(x = rank, y = count)) + geom_point()
```
